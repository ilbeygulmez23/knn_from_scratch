{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7b402a1"
      },
      "source": [
        "# ASSIGNMENT 1 SOLUTION"
      ],
      "id": "b7b402a1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73207c93"
      },
      "source": [
        "## Part 1"
      ],
      "id": "73207c93"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ce8baa8"
      },
      "source": [
        "### k-Nearest Neighbor Classification"
      ],
      "id": "1ce8baa8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79092fad"
      },
      "source": [
        "Answer 1 :\n",
        "\n",
        "kNN wouldn't be a great idea in larger datasets because;\n",
        "\n",
        "1: It is computationally expensive since in a large dataset the algorithm of the kNN would be time-consuming and memory-intensive.\n",
        "\n",
        "2: kNN is sensitive to irrelevant data, outliers and high dimensions. These matters would make it hard for kNN to produce good results, making the model impractical."
      ],
      "id": "79092fad"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5d9997b9"
      },
      "source": [
        "Answer 2:\n",
        "\n",
        "The optimal value of k is 10 because it has the lowest validation error.\n",
        "It is overfitting for the values lower than 10 and underfitting for the values higher."
      ],
      "id": "5d9997b9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1863704"
      },
      "source": [
        "Answer 3:"
      ],
      "id": "c1863704"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cf692a4"
      },
      "source": [
        "K = 1 wouldn't be suitable because it would overfit the data since it predicts the 1st nearest neighbor for each prediction."
      ],
      "id": "7cf692a4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1a267bf4"
      },
      "source": [
        "K = 3 would be better because model will be more generalized since it takes 3 neighbors in calculation."
      ],
      "id": "1a267bf4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "167f78af"
      },
      "source": [
        "K = 5 wouldn't be suitable because model will underfit the data, model would generalize too much."
      ],
      "id": "167f78af"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9bac889"
      },
      "source": [
        "Answer 4:"
      ],
      "id": "a9bac889"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df26c9b1"
      },
      "source": [
        "If all instances of the data have the same scale then k-Nearest Neighbor’s performance increases drastically. (T)\n",
        "\n",
        "While k-Nearest Neighbor performs well with a small number of input variables, it’s performance decreases when the number of inputs becomes large. (T)\n",
        "\n",
        "k-Nearest Neighbor makes supposes nothing about the functional form of the\n",
        "problem it handles. (T)"
      ],
      "id": "df26c9b1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e997a53"
      },
      "source": [
        "### Linear Regression"
      ],
      "id": "0e997a53"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f3b6107"
      },
      "source": [
        "Answer 1:"
      ],
      "id": "9f3b6107"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e2d02a5",
        "outputId": "759c09ee-53d8-42d6-bd0c-1412cebf5246"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Normalized value of x2(5) is 0.073779\n"
          ]
        }
      ],
      "source": [
        "x2_real = 2025\n",
        "sum_x2 = 7569 + 4900 + 8464 + 4489 + 2025\n",
        "x2_normalized = x2_real / sum_x2\n",
        "print(\"Normalized value of x2(5) is %f\"%x2_normalized)"
      ],
      "id": "5e2d02a5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e21e58c9"
      },
      "source": [
        "Answer 2:"
      ],
      "id": "e21e58c9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cc423da"
      },
      "source": [
        "Perpendicular offset is better because we use the shortest distance."
      ],
      "id": "1cc423da"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fa8f9a31"
      },
      "source": [
        "Answer 3:"
      ],
      "id": "fa8f9a31"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52a8f1eb",
        "outputId": "829093cc-4750-4d3c-95fe-6bf248e958a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "θ1 and θ2 are : [2.77555756e-16 5.00000000e-01]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the feature matrix X and the target vector y\n",
        "x = np.array([[1, 1], [1, 2], [1, 4], [1, 0]])\n",
        "y = np.array([0.5, 1, 2, 0])\n",
        "\n",
        "x_transpose = x.transpose()  # [[1, 1, 1, 1], [1, 2, 4, 0]]\n",
        "\n",
        "# Calculate X^T * X\n",
        "x_transpose_multiply_x = np.dot(x_transpose, x)\n",
        "\n",
        "# Calculate the inverse of X^T * X\n",
        "invert_x_t_x = np.linalg.inv(x_transpose_multiply_x)\n",
        "\n",
        "# Calculate X^T * y\n",
        "x_transpose_multiply_y = np.dot(x_transpose, y)\n",
        "\n",
        "# Calculate the model coefficients θ\n",
        "model = np.dot(invert_x_t_x, x_transpose_multiply_y)\n",
        "print(\"θ1 and θ2 are :\",end = \" \")\n",
        "print(model)"
      ],
      "id": "52a8f1eb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b48b2777"
      },
      "source": [
        "Answer 4:"
      ],
      "id": "b48b2777"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cf7f239"
      },
      "source": [
        "Using feature scaling, features will contribute equally to dataset thanks to weights and normalization. If different features have different scalings;using a distance-based model like kNN would make features that have larger numerical values affect more the model trained. Scaling also leads to faster convergence of the model."
      ],
      "id": "7cf7f239"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df0e6ae3"
      },
      "source": [
        "## Part 2"
      ],
      "id": "df0e6ae3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTV-UFSmYXEB"
      },
      "source": [
        "## Anime Recommendation System"
      ],
      "id": "yTV-UFSmYXEB"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7aN15Svhk10"
      },
      "source": [
        "Import necessary libraries and authenticate the user for the drive link provided"
      ],
      "id": "c7aN15Svhk10"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANCSDqicZNq1"
      },
      "outputs": [],
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "import io\n",
        "\n",
        "auth.authenticate_user()\n",
        "google_auth = GoogleAuth()\n",
        "google_auth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(google_auth)\n"
      ],
      "id": "ANCSDqicZNq1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6K3DvNfghtMP"
      },
      "source": [
        "Define necessary functions to read content directly from the link without downloading it"
      ],
      "id": "6K3DvNfghtMP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eP7VoZEueg_X"
      },
      "outputs": [],
      "source": [
        "def read_content_from_drive(file_id,file_name):\n",
        "  downloaded = drive.CreateFile({'id' : file_id})\n",
        "  downloaded.GetContentFile(file_name)"
      ],
      "id": "eP7VoZEueg_X"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hMGWA2wfLob"
      },
      "outputs": [],
      "source": [
        "def read_content_from_zipfile(file):\n",
        "  with zipfile.ZipFile(\"Dataset_A1.zip\",\"r\") as zip_file:\n",
        "    with zip_file.open(file) as file_raw:\n",
        "      file_data = file_raw.read()\n",
        "    df = pd.read_csv(io.BytesIO(file_data))\n",
        "  return df"
      ],
      "id": "5hMGWA2wfLob"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZdG9T2yh4lx"
      },
      "source": [
        "Read the contents by calling the functions"
      ],
      "id": "eZdG9T2yh4lx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-sGOKaNHaMwO"
      },
      "outputs": [],
      "source": [
        "read_content_from_drive(\"1kCL8dZLHQUlBUzH-DmYHRNi7xMLrgS4b\",\"Dataset_A1.zip\")\n",
        "animes = read_content_from_zipfile(\"animes.csv\")\n",
        "user_rates_train = read_content_from_zipfile(\"user_rates_train.csv\")\n",
        "user_rates_test = read_content_from_zipfile(\"user_rates_test.csv\")"
      ],
      "id": "-sGOKaNHaMwO"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o59C0V45Pwpv"
      },
      "source": [
        "### Preprocessing\n",
        "\n",
        "We do all the process for both datasets"
      ],
      "id": "o59C0V45Pwpv"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVI__P1d0bqV"
      },
      "source": [
        "Extract Anime names, Usernames,Studios and Image URL from data"
      ],
      "id": "DVI__P1d0bqV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmw4nEsUNxG_"
      },
      "outputs": [],
      "source": [
        "animes.drop([\"Image URL\",\"Name\",\"Studios\"],axis = 1,inplace = True)\n",
        "user_rates_train.drop([\"Username\",\"Anime Title\"], axis = 1, inplace = True)\n",
        "user_rates_test.drop([\"Username\",\"Anime Title\"], axis = 1, inplace = True)"
      ],
      "id": "bmw4nEsUNxG_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### All process is done for the both test and train datasets"
      ],
      "metadata": {
        "id": "flucHh6ieR91"
      },
      "id": "flucHh6ieR91"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZrYC9381SQ2"
      },
      "source": [
        "Merge the user rates and animes dataset under 'anime_id' column"
      ],
      "id": "kZrYC9381SQ2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04dju9j31W37"
      },
      "outputs": [],
      "source": [
        "df_train = pd.merge(animes,user_rates_train, on = \"anime_id\", how = \"inner\")\n",
        "df_test = pd.merge(animes,user_rates_test, on = \"anime_id\", how = \"inner\")"
      ],
      "id": "04dju9j31W37"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qq2jIq4n36IJ"
      },
      "source": [
        "Adjust the Genre column to encode"
      ],
      "id": "qq2jIq4n36IJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqET0B044KAa"
      },
      "outputs": [],
      "source": [
        "#For df_test\n",
        "genre_split = df_test['Genres'].str.split(', ', expand=True) #Split the line into 3 elements\n",
        "genre_split = genre_split.iloc[:,:3]\n",
        "column_names = {0 : 'Genre1',1 : 'Genre2', 2 : 'Genre3'}  #Arrange the dataframe for Genres\n",
        "genre_split = genre_split.rename(columns = column_names)\n",
        "df_test = pd.concat([df_test,genre_split],axis = 1) #Concatenate the dataframes\n",
        "df_test = df_test.drop(columns = ['Genres'])\n",
        "\n",
        "\n",
        "#For df_train\n",
        "genre_split = df_train['Genres'].str.split(', ', expand=True)\n",
        "genre_split = genre_split.iloc[:,:3]\n",
        "column_names = {0 : 'Genre1',1 : 'Genre2', 2 : 'Genre3'}\n",
        "genre_split = genre_split.rename(columns = column_names)\n",
        "df_train = pd.concat([df_train,genre_split],axis = 1)\n",
        "df_train = df_train.drop(columns = ['Genres'])"
      ],
      "id": "DqET0B044KAa"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fsk15SY9N5pH"
      },
      "source": [
        "Adjust the Duration column to encode"
      ],
      "id": "Fsk15SY9N5pH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_p3YgEXDoUW"
      },
      "outputs": [],
      "source": [
        "#For df_train\n",
        "duration_list = []   #Arrange the format of the duration cells\n",
        "for i in df_train['Duration']:\n",
        "  cell_list = i.split(\" \")\n",
        "  if cell_list[1] == 'hr':\n",
        "    duration_list.append(int(cell_list[0]) * 60)\n",
        "  elif cell_list[1] == 'min':\n",
        "    duration_list.append(int(cell_list[0]))\n",
        "  else:\n",
        "    duration_list.append(0.5)\n",
        "df_train = df_train.drop(columns = ['Duration'])\n",
        "duration_df = pd.DataFrame(duration_list,columns = ['Duration'])\n",
        "df_train = pd.concat([df_train,duration_df] , axis = 1)\n",
        "\n",
        "\n",
        "\n",
        "#For df_test\n",
        "duration_list = []\n",
        "for i in df_test['Duration']:\n",
        "  cell_list = i.split(\" \")\n",
        "  if cell_list[1] == 'hr':\n",
        "    duration_list.append(int(cell_list[0]) * 60)\n",
        "  elif cell_list[1] == 'min':\n",
        "    duration_list.append(int(cell_list[0]))\n",
        "  else:\n",
        "    duration_list.append(0.5)\n",
        "df_test = df_test.drop(columns = ['Duration'])\n",
        "duration_df = pd.DataFrame(duration_list,columns = ['Duration'])\n",
        "df_test = pd.concat([df_test,duration_df] , axis = 1)"
      ],
      "id": "Q_p3YgEXDoUW"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcegHRjyOKU1"
      },
      "source": [
        "Label Encoding"
      ],
      "id": "YcegHRjyOKU1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rlxier2zODBA"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "columns_to_encode = ['Type','Source',\"Genre1\",\"Genre2\",\"Genre3\"]\n",
        "for col in columns_to_encode:\n",
        "  df_train[col] = label_encoder.fit_transform(df_train[col])\n",
        "\n",
        "\n",
        "for col in columns_to_encode:\n",
        "  df_test[col] = label_encoder.fit_transform(df_test[col])\n",
        "\n"
      ],
      "id": "Rlxier2zODBA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Zp1NAzVYf59"
      },
      "source": [],
      "id": "0Zp1NAzVYf59"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_ZE03m_Dabr"
      },
      "source": [
        "### Split both datasets\n"
      ],
      "id": "o_ZE03m_Dabr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xaoHa1tKD9V1"
      },
      "outputs": [],
      "source": [
        "x_train = df_train.drop('rating',axis = 1)\n",
        "y_train = df_train['rating']\n",
        "\n",
        "x_test = df_test.drop('rating',axis = 1)\n",
        "y_test = df_test['rating']"
      ],
      "id": "xaoHa1tKD9V1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBex-554Ru_Z"
      },
      "source": [
        "Define a function that implements kNN and calculates Mean Absolute Error"
      ],
      "id": "hBex-554Ru_Z"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rzo_rGsM0DMY"
      },
      "outputs": [],
      "source": [
        "def knn_and_error(k):\n",
        "\n",
        "  total_error = 0\n",
        "\n",
        "  for test_index in range(len(x_test)):\n",
        "\n",
        "    vector1 = x_test.iloc[test_index]\n",
        "\n",
        "    similarities = {}\n",
        "\n",
        "    for train_index in range(len(x_train)):\n",
        "      vector2 = x_train.iloc[train_index]\n",
        "      similarities[train_index] = np.dot(vector1, vector2) / (np.linalg.norm(vector1) * np.linalg.norm(vector2)) #Calculate the similarities and add them to dictionaries.\n",
        "\n",
        "    similarities = dict(sorted(similarities.items(), key=lambda item: item[1],reverse = True))\n",
        "\n",
        "    top_k_similarities = (list(similarities.items())[:k])   #Get top k similarities\n",
        "\n",
        "    predicted_rate = 0      #Calculate the errors\n",
        "\n",
        "    for similarity_score in top_k_similarities:\n",
        "      predicted_rate += y_train.iloc[similarity_score[0]]\n",
        "\n",
        "    error = abs((predicted_rate/k) - y_test.iloc[test_index])\n",
        "    total_error += error\n",
        "\n",
        "  mean_absolute_error = total_error / len(x_test)\n",
        "  return f\"Mean absolute error for k = {k} is {mean_absolute_error}\""
      ],
      "id": "Rzo_rGsM0DMY"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fi9huYE-M90-"
      },
      "source": [
        "Report the results for k = 3, 5, 7"
      ],
      "id": "fi9huYE-M90-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CTp-aRbnM_7X",
        "outputId": "2a063f0f-2533-457e-a772-3e492c3a81b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean absolute error for k = 3 is 1.359179019384265\n"
          ]
        }
      ],
      "source": [
        "print(knn_and_error(3))"
      ],
      "id": "CTp-aRbnM_7X"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwDhA1r3B3UC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3325005-f670-4989-8d4d-3644ff4e53f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean absolute error for k = 5 is 1.2884834663626017\n"
          ]
        }
      ],
      "source": [
        "print(knn_and_error(5))"
      ],
      "id": "QwDhA1r3B3UC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-f5vZbANB5qC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6a8c2c9-51d4-4d37-8db1-048c7240b790"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean absolute error for k = 7 is 1.2480860074930784\n"
          ]
        }
      ],
      "source": [
        "print(knn_and_error(7))"
      ],
      "id": "-f5vZbANB5qC"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TFrmtI_NBJy"
      },
      "source": [
        "## Report"
      ],
      "id": "2TFrmtI_NBJy"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Introduction"
      ],
      "metadata": {
        "id": "NyShv1wslKD8"
      },
      "id": "NyShv1wslKD8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyAl1Qo2Rqrn"
      },
      "source": [
        "In this report, we present the development and evaluation of an anime recommendation system using a K-Nearest Neighbors (KNN) algorithm based on cosine similarity. The goal of this project was to recommend anime titles to users based on their viewing history and user ratings. The dataset consisted of two parts: an anime dataset with anime information and a user_rating dataset with user ratings. We divided the data into training and testing sets to evaluate the recommendation algorithm's performance.\n"
      ],
      "id": "AyAl1Qo2Rqrn"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preprocessing"
      ],
      "metadata": {
        "id": "h7ASK0OvlWXg"
      },
      "id": "h7ASK0OvlWXg"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We loaded the anime dataset and user_rating dataset separately.\n",
        "\n",
        "Split the data into training and testing sets.\n",
        "\n",
        "Handled missing values and data cleaning.\n",
        "\n",
        "Ensured that the user_rating dataset was appropriately aligned with the anime dataset."
      ],
      "metadata": {
        "id": "kMfSV6x-lZzU"
      },
      "id": "kMfSV6x-lZzU"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### K-Nearest Neighbors Algorithm:"
      ],
      "metadata": {
        "id": "d5hj5nTWlqTe"
      },
      "id": "d5hj5nTWlqTe"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We implemented a KNN algorithm using cosine similarity.\n",
        "\n",
        "The K parameter (number of nearest neighbors) was a crucial hyperparameter to determine the performance of the algorithm."
      ],
      "metadata": {
        "id": "wWw-8QIql0DP"
      },
      "id": "wWw-8QIql0DP"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Evaluation:"
      ],
      "metadata": {
        "id": "zasq4I8Rl-xb"
      },
      "id": "zasq4I8Rl-xb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We evaluated the KNN recommendation algorithm on the test dataset.\n",
        "\n",
        "We varied the value of K to identify the optimal K for the lowest Mean Absolute Error (MAE).\n"
      ],
      "metadata": {
        "id": "F3CSXXdhmDOA"
      },
      "id": "F3CSXXdhmDOA"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Results"
      ],
      "metadata": {
        "id": "0sEXef0ymKvU"
      },
      "id": "0sEXef0ymKvU"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "After experimenting with different values of K, we observed that K = 7 produced the lowest Mean Absolute Error (MAE) when comparing the predicted user ratings with the actual user ratings. This suggests that considering the seven nearest neighbors produced the most accurate anime recommendations based on user preferences and viewing history."
      ],
      "metadata": {
        "id": "P7WFXq86mNIp"
      },
      "id": "P7WFXq86mNIp"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Conclusion"
      ],
      "metadata": {
        "id": "G7mbR5BkmV7I"
      },
      "id": "G7mbR5BkmV7I"
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project, we successfully developed an anime recommendation system using the K-Nearest Neighbors algorithm with cosine similarity. We concluded that setting K to 7 provides the best recommendation performance, as it resulted in the lowest MAE on our test dataset. This means that considering the seven nearest neighbors when making recommendations led to more accurate and personalized anime recommendations for users. The system can be further improved and deployed for anime enthusiasts to enhance their viewing experiences. Further refinements could include incorporating user-based or item-based collaborative filtering, or even leveraging more advanced recommendation algorithms.\n"
      ],
      "metadata": {
        "id": "x4FSICOsmZHf"
      },
      "id": "x4FSICOsmZHf"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}